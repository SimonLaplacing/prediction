{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T02:54:06.359421Z",
     "start_time": "2022-01-06T02:54:02.227018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.546 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from nuscenes import NuScenes\n",
    "\n",
    "# This is the path where you stored your copy of the nuScenes dataset.\n",
    "DATAROOT = 'E:/Downloads/nuscenes'\n",
    "\n",
    "nuscenes = NuScenes('v1.0-mini', dataroot=DATAROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T02:54:12.064517Z",
     "start_time": "2022-01-06T02:54:11.970781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742 32186 9041\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "mini_train = get_prediction_challenge_split(\"mini_train\", dataroot=DATAROOT)\n",
    "train = get_prediction_challenge_split(\"train\", dataroot=DATAROOT)\n",
    "val = get_prediction_challenge_split(\"val\", dataroot=DATAROOT)\n",
    "print(len(mini_train), len(train), len(val))  # train-val大约8：2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T03:27:13.223683Z",
     "start_time": "2022-01-06T03:27:13.155673Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-11896fdf67d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mpast_xy_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_past_for_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_agent_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast_xy_local\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpast_xy_local\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mfuture_xy_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_future_for_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_agent_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# print(future_xy_local)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# 轨迹序列\n",
    "from nuscenes.prediction import PredictHelper\n",
    "helper = PredictHelper(nuscenes)\n",
    "# instance_token, sample_token = [i.split(\"_\") for i in mini_train]\n",
    "instance_token = []\n",
    "sample_token = []\n",
    "for i in mini_train:\n",
    "    token = i.split(\"_\")\n",
    "    i_token, s_token = token\n",
    "    instance_token.append(i_token)\n",
    "    sample_token.append(s_token)\n",
    "\n",
    "past_xy_local = [helper.get_past_for_agent(instance_token[i], sample_token[i], seconds=1, in_agent_frame=True).tolist() for i in range(len(instance_token))] \n",
    "print(past_xy_local)\n",
    "future_xy_local = [helper.get_future_for_agent(instance_token[i], sample_token[i], seconds=5, in_agent_frame=True) for i in range(len(instance_token))]\n",
    "# print(future_xy_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T03:07:03.129104Z",
     "start_time": "2022-01-06T03:07:02.275155Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
    "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
    "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
    "\n",
    "static_layer_rasterizer = StaticLayerRasterizer(helper)\n",
    "agent_rasterizer = AgentBoxesWithFadedHistory(helper, seconds_of_history=0)\n",
    "mtp_input_representation = InputRepresentation(static_layer_rasterizer, agent_rasterizer, Rasterizer())\n",
    "\n",
    "instance_token_img, sample_token_img = instance_token, sample_token\n",
    "# anns = [ann for ann in nuscenes.sample_annotation if ann['instance_token'] == instance_token_img]\n",
    "img = mtp_input_representation.make_input_representation(instance_token_img, sample_token_img)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T08:34:51.227359Z",
     "start_time": "2022-01-05T08:34:47.763906Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim,Tensor,unsqueeze\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50,resnet18\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=train_cfg[\"shuffle\"], \n",
    "    batch_size=train_cfg[\"batch_size\"],\n",
    "    num_workers=train_cfg[\"num_workers\"],\n",
    "    prefetch_factor = 2,\n",
    "    pin_memory = True,\n",
    "    persistent_workers=True,\n",
    "    worker_init_fn=my_dataset_worker_init_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "if cfg[\"train_params\"][\"device\"] == 1:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "epochs = cfg[\"train_params\"][\"epochs\"]\n",
    "latent_dim = cfg[\"model_params\"][\"latent_dim\"]  # LSTM 的单元个数\n",
    "encoder_fc = 64\n",
    "num_layers = cfg[\"model_params\"][\"num_layers\"]\n",
    "bidirectional = cfg[\"model_params\"][\"bidirectional\"]\n",
    "\n",
    "encoder_length = cfg[\"model_params\"][\"history_num_frames\"]\n",
    "decoder_length = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2\n",
    "z_dimension = 32\n",
    "accumulation_steps = 5 # 梯度累积步数\n",
    "\n",
    "num_classes = 3 # 类数\n",
    "modal_fc = latent_dim*(1+bidirectional) \n",
    "thre = 0.175 # yaw_threshold=10°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "\n",
    "        # 定义序列编码器\n",
    "        self.encoder = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.encoder2 = nn.Linear(latent_dim*(1+bidirectional), encoder_fc)\n",
    "#         self.encoder2 = nn.Linear(latent_dim*(1+bidirectional)+modal_fc, encoder_fc)\n",
    "#         self.encoder_mean1 = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.encoder_mean2 = nn.Linear(encoder_fc, z_dimension)\n",
    "#         self.encoder_std1 = nn.Linear(latent_dim*(1+bidirectional), 32)\n",
    "        self.encoder_std2 = nn.Linear(encoder_fc, z_dimension)\n",
    "\n",
    "        # 定义序列解码器\n",
    "        self.decoder = nn.LSTM(z_dimension*2, latent_dim, num_layers=num_layers,\n",
    "                               bidirectional=bidirectional, batch_first=True)\n",
    "        self.decoder_fc = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.decoder_fc1 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_fc2 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_fc3 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_confi = nn.Linear(6, num_classes)\n",
    "\n",
    "        # 定义图像编码器\n",
    "        # load pre-trained Conv2D model\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        # change input channels number to match the rasterizer's output\n",
    "        num_history_channels = (\n",
    "            cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.resnet.conv1.out_channels,\n",
    "            kernel_size=self.resnet.conv1.kernel_size,\n",
    "            stride=self.resnet.conv1.stride,\n",
    "            padding=self.resnet.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        # change output size to (X, Y) * number of future states\n",
    "        num_targets = z_dimension * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.encoder_mean3 = nn.Linear(512, num_targets)\n",
    "        self.encoder_std3 = nn.Linear(512, num_targets)\n",
    "        \n",
    "        #定义采样器\n",
    "        self.sampler_fc1 = nn.Linear(3,1024)\n",
    "        self.sampler_fc2 = nn.Linear(1024,512)\n",
    "        self.sampler_fc3 = nn.Linear(512,z_dimension * cfg[\"model_params\"][\"future_num_frames\"])\n",
    "        \n",
    "        #定义行为预测\n",
    "        self.modal1 = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.modal2 = nn.Linear(latent_dim*(1+bidirectional), 3)\n",
    "        \n",
    "    def noise_reparameterize(self, mean, logvar):\n",
    "        eps = torch.randn(mean.shape).to(device)\n",
    "        z = mean + eps * torch.exp(logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, data):\n",
    "        inputs1 = torch.FloatTensor(data[\"history_positions\"]).to(device)\n",
    "#         yaw = torch.FloatTensor(data[\"history_yaws\"]).to(device)\n",
    "        if inputs1.dim() == 2:\n",
    "            inputs1 = torch.unsqueeze(inputs1, 0)\n",
    "\n",
    "        h0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        c0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "\n",
    "        inputs2 = torch.FloatTensor(data[\"image\"]).to(device)\n",
    "        if inputs2.dim() == 3:\n",
    "            inputs2 = torch.unsqueeze(inputs2, 0)\n",
    "\n",
    "        out1, _ = self.encoder(inputs1, (h0, c0))\n",
    "#         out1 = out1[:,-1,:]\n",
    "#         out1 = torch.unsqueeze(out1, 1)\n",
    "#         out1 = out1.expand(out1.size()[0],decoder_length,out1.size()[-1])\n",
    "        out1 = F.relu(self.encoder2(out1), inplace=True)\n",
    "        \n",
    "        out_modal, _ = self.modal1(inputs1, (h0, c0))\n",
    "        out_modal = F.softmax(self.modal2(out_modal[:, -1, :]), dim = -1)\n",
    "\n",
    "#         mean1 = F.relu(self.encoder_mean1(out1), inplace=True)\n",
    "        mean2 = F.relu(self.encoder_mean2(out1), inplace=True)\n",
    "#         logstd1 = F.relu(self.encoder_std1(out1), inplace=True)\n",
    "        logstd2 = F.relu(self.encoder_std2(out1), inplace=True)\n",
    "        # prevent from poster vanish\n",
    "#         logstd2 = torch.abs(logstd2) + 0.6\n",
    "\n",
    "        z1 = self.noise_reparameterize(mean2, logstd2)\n",
    "        z1 = z1[:, -1, :]\n",
    "        z1 = torch.unsqueeze(z1, 1)\n",
    "        z1 = z1.expand(z1.size()[0], decoder_length, z1.size()[-1])\n",
    "\n",
    "        out12 = self.resnet(inputs2)\n",
    "        mean3 = F.relu(self.encoder_mean3(out12), inplace=True)\n",
    "        logstd3 = F.relu(self.encoder_std3(out12), inplace=True)\n",
    "        z2 = self.noise_reparameterize(mean3, logstd3)\n",
    "        z2 = z2.reshape(z1.size())\n",
    "        z = torch.cat([z1, z2], -1)\n",
    "        out2, _ = self.decoder(z)\n",
    "        out2 = F.relu(self.decoder_fc(out2), inplace=True)\n",
    "\n",
    "        out21 = F.relu(self.decoder_fc1(out2), inplace=True)\n",
    "        out22 = F.relu(self.decoder_fc2(out2), inplace=True)\n",
    "        out23 = F.relu(self.decoder_fc3(out2), inplace=True)\n",
    "        confs = torch.cat([out21, out22, out23], dim=-1)\n",
    "        confidences = F.softmax(self.decoder_confi(confs)[:, -1, :], dim=-1)\n",
    "        confidences = F.softmax(confidences * out_modal, dim=-1)\n",
    "        \n",
    "        out21 = torch.unsqueeze(out21, 1)\n",
    "        out22 = torch.unsqueeze(out22, 1)\n",
    "        out23 = torch.unsqueeze(out23, 1)\n",
    "        y_hat = torch.cat([out21, out22, out23], dim=1)\n",
    "\n",
    "        return y_hat, confidences, mean2, logstd2, mean3, logstd3\n",
    "\n",
    "\n",
    "def label_maker(yaw):\n",
    "    yaw = yaw.squeeze()\n",
    "#     print(yaw.size())\n",
    "    ind = torch.argmax(torch.abs(yaw), dim=-1)\n",
    "#     print(ind.size())\n",
    "    yaw = yaw[torch.arange(len(yaw)), ind]\n",
    "    yaw = yaw.unsqueeze(dim=-1)\n",
    "    w = torch.cat([yaw, yaw, yaw], dim=-1)\n",
    "    one = torch.ones_like(yaw)\n",
    "    label1 = torch.tensor([0., 0., 1.]).to(device)\n",
    "    label1 = label1.expand(len(yaw), num_classes)\n",
    "    label2 = torch.tensor([0., 1., 0.]).to(device)\n",
    "    label2 = label2.expand(len(yaw), num_classes)\n",
    "    label3 = torch.tensor([1., 0., 0.]).to(device)\n",
    "    label3 = label3.expand(len(yaw), num_classes)\n",
    "\n",
    "    w = torch.where(yaw >= thre, label1, w)\n",
    "    yaw = torch.where(yaw >= thre, one, yaw)\n",
    "\n",
    "    w = torch.where(yaw <= -thre, label3, w)\n",
    "    yaw = torch.where(yaw <= -thre, one, yaw)\n",
    "\n",
    "    w = torch.where(yaw < thre, label2, w)\n",
    "#     w = torch.LongTensor(w).to(device)\n",
    "    return w\n",
    "\n",
    "\n",
    "def loss_function(y_hat, confidences, data, mean1, std1, mean2, std2):\n",
    "    y_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    yaw = data[\"target_yaws\"].to(device)\n",
    "    label = label_maker(yaw)\n",
    "    y_true = data[\"target_positions\"].to(device)\n",
    "#     MSE = F.mse_loss(y_hat, y_true, reduction='none')\n",
    "#     MSE = MSE * y_availabilities\n",
    "#     MSE = MSE.mean()\n",
    "    Cross = F.binary_cross_entropy_with_logits(confidences, label)\n",
    "    NLL = neg_multi_log_likelihood_batch(\n",
    "        y_true, y_hat, confidences, y_availabilities)\n",
    "    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n",
    "    var1 = torch.pow(torch.exp(std1), 2)\n",
    "    var2 = torch.pow(torch.exp(std2), 2)\n",
    "    KLD1 = -0.5 * torch.mean(1+torch.log(var1)-torch.pow(mean1, 2)-var1)\n",
    "    KLD1 = torch.max(KLD1,torch.ones_like(KLD1))\n",
    "    KLD2 = -0.5 * torch.mean(1+torch.log(var2)-torch.pow(mean2, 2)-var2)\n",
    "    KLD2 = torch.max(KLD2,torch.ones_like(KLD2))\n",
    "    KLD = KLD1 + KLD2\n",
    "#     print('KLD: ',KLD,' NLL: ',NLL,' Cross: ', Cross)\n",
    "    return NLL, KLD, Cross\n",
    "\n",
    "\n",
    "# 创建对象\n",
    "cvae = CVAE().to(device)\n",
    "# vae.load_state_dict(torch.load('./VAE_z2.pth'))\n",
    "cvae_optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg['mode']['load_mode']:    \n",
    "    # ==== TRAIN LOOP\n",
    "    losses_avg = []\n",
    "    for epoch in range(epochs):  # 进行多个epoch的训练\n",
    "        tr_it = iter(train_dataloader)\n",
    "        progress_bar = tqdm(range(len(train_dataloader)//1),position=0)\n",
    "        losses_train = []\n",
    "        cvae_optimizer.zero_grad(set_to_none = True)\n",
    "        for i in progress_bar:\n",
    "            try:\n",
    "                data = next(tr_it)\n",
    "            except StopIteration:\n",
    "                tr_it = iter(train_dataloader)\n",
    "                data = next(tr_it)\n",
    "            cvae.train() # 设置为训练模式\n",
    "            torch.set_grad_enabled(True)\n",
    "            y_hat, confidences, mean1, std1, mean2, std2 = cvae(data)  # 输入\n",
    "            if cfg[\"train_params\"][\"device\"] == 1:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    NLL,KLD,Cross = loss_function(y_hat, confidences, data, mean1, std1, mean2, std2)\n",
    "                    loss = NLL + (25)*KLD + 20*Cross\n",
    "                    if i + 1>= len(train_dataloader)//1:\n",
    "                        print(NLL,KLD,Cross)\n",
    "            else:\n",
    "                NLL,KLD,Cross = loss_function(y_hat, confidences, data, mean1, std1, mean2, std2)\n",
    "                loss = NLL + (25)*KLD + 20*Cross\n",
    "                if i + 1>= len(train_dataloader)//1:\n",
    "                    print(NLL,KLD,Cross)\n",
    "\n",
    "            # Backward pass\n",
    "            # 梯度累积模式\n",
    "            loss = loss / accumulation_steps\n",
    "            loss.backward() \n",
    "            if (i+1) % accumulation_steps == 0:\n",
    "                cvae_optimizer.step()\n",
    "                cvae_optimizer.zero_grad(set_to_none = True)\n",
    "\n",
    "            # 无梯度累积模式\n",
    "    #         cvae_optimizer.zero_grad(set_to_none = True)\n",
    "    #         loss.backward()\n",
    "    #         cvae_optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "            progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "        losses_avg.append(np.mean(losses_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python {lgsvl}",
   "language": "python",
   "name": "lgsvl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
