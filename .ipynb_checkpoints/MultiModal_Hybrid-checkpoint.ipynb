{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\l5kit\\dataset\\select_agents.py:32: UserWarning: Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.However, writing the mask with this config may be inconsistent.\n",
      "  \"Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.\"\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50,resnet18\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mydataset import MyTrainDataset, my_dataset_worker_init_func\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, write_gt_csv, read_gt_csv\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace, average_displacement_error_mean, final_displacement_error_mean\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_version': 4, 'model_params': {'model_architecture': 'CVAE', 'latent_dim': 128, 'num_layers': 2, 'bidirectional': True, 'history_step_size': 1, 'history_num_frames': 49, 'future_step_size': 1, 'future_num_frames': 50, 'step_time': 0.1, 'render_ego_history': True}, 'raster_params': {'raster_size': [224, 224], 'pixel_size': [0.5, 0.5], 'ego_center': [0.25, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'train_data_loader': {'key': 'scenes/sample.zarr', 'batch_size': 32, 'shuffle': True, 'num_workers': 2}, 'val_data_loader': {'key': 'scenes/sample.zarr', 'batch_size': 32, 'shuffle': False, 'num_workers': 2}, 'train_params': {'checkpoint_every_n_steps': 10000, 'epochs': 1, 'eval_every_n_steps': 10000}}\n"
     ]
    }
   ],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"E:/Downloads/lyft-motion-prediction-autonomous-vehicles\"\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(\"./agent_motion_config.yaml\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111634\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|    100     |   24838    |  1893736   |     316008    |       0.69      |        248.38        |        76.24         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', 'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', 'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'curr_speed', 'scene_index', 'host_id', 'timestamp', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT DATASET\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "print(len(train_dataset))\n",
    "print(train_dataset)\n",
    "print(train_dataset[0].keys())\n",
    "\n",
    "train_dataset = MyTrainDataset(cfg, dm, len(train_dataset),raster_mode = 1)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=train_cfg[\"shuffle\"], \n",
    "    batch_size=train_cfg[\"batch_size\"],\n",
    "    num_workers=train_cfg[\"num_workers\"],\n",
    "    persistent_workers=True,\n",
    "    worker_init_fn=my_dataset_worker_init_func\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "epochs = cfg[\"train_params\"][\"epochs\"]\n",
    "latent_dim = cfg[\"model_params\"][\"latent_dim\"]  # LSTM 的单元个数\n",
    "num_layers = cfg[\"model_params\"][\"num_layers\"]\n",
    "bidirectional = cfg[\"model_params\"][\"bidirectional\"]\n",
    "num_classes = 3 # 类数\n",
    "encoder_length = cfg[\"model_params\"][\"history_num_frames\"]\n",
    "decoder_length = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2\n",
    "z_dimension = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "        # 定义编码器\n",
    "        self.encoder = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.encoder2 = nn.Linear(latent_dim*(1+bidirectional),16)\n",
    "#         self.encoder_mean1 = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.encoder_mean2 = nn.Linear(16*2, z_dimension)\n",
    "#         self.encoder_std1 = nn.Linear(latent_dim*(1+bidirectional), 32)\n",
    "        self.encoder_std2 = nn.Linear(16*2, z_dimension)\n",
    "        self.decoder = nn.LSTM(z_dimension, latent_dim, num_layers=num_layers,\n",
    "                               bidirectional=bidirectional, batch_first=True)\n",
    "        self.decoder_fc1 = nn.Linear(latent_dim*(1+bidirectional), 32)\n",
    "        self.decoder_fc2 = nn.Linear(32, 16)\n",
    "        self.decoder_fc3 = nn.Linear(16, num_decoder_tokens)\n",
    "        \n",
    "        # load pre-trained Conv2D model\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        \n",
    "        # change input channels number to match the rasterizer's output\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.resnet.conv1.out_channels,\n",
    "            kernel_size=self.resnet.conv1.kernel_size,\n",
    "            stride=self.resnet.conv1.stride,\n",
    "            padding=self.resnet.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        # change output size to (X, Y) * number of future states\n",
    "        num_targets = 16 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=num_targets)\n",
    "\n",
    "    def noise_reparameterize(self, mean, logvar):\n",
    "        eps = torch.randn(mean.shape).to(device)\n",
    "        z = mean + eps * torch.exp(logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, data):\n",
    "        inputs1 = torch.FloatTensor(data[\"history_positions\"]).to(device)\n",
    "        if inputs1.dim() == 2:\n",
    "            inputs1.resize_(1, inputs1.size()[0], inputs1.size()[1])\n",
    "#         print(inputs.size())\n",
    "        h0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        c0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        inputs2 = data[\"image\"].to(device)\n",
    "\n",
    "        out11, _ = self.encoder(inputs1, (h0, c0))\n",
    "        out11 = F.relu(self.encoder2(out11), inplace=True)\n",
    "        out12 = self.resnet(inputs2).reshape(out11.size())\n",
    "        out1 = torch.cat([out11,out12],2)\n",
    "#         print(out1.size())\n",
    "#         mean1 = F.relu(self.encoder_mean1(out1), inplace=True)\n",
    "        mean2 = F.relu(self.encoder_mean2(out1), inplace=True)\n",
    "#         logstd1 = F.relu(self.encoder_std1(out1), inplace=True)\n",
    "        logstd2 = F.relu(self.encoder_std2(out1), inplace=True)\n",
    "        z = self.noise_reparameterize(mean2, logstd2)\n",
    "        out2, _ = self.decoder(z)\n",
    "        out2 = F.relu(self.decoder_fc1(out2), inplace=True)\n",
    "        out2 = F.relu(self.decoder_fc2(out2), inplace=True)\n",
    "        y_hat = self.decoder_fc3(out2)\n",
    "        return y_hat, mean2, logstd2\n",
    "\n",
    "\n",
    "def loss_function(y_hat, data, mean, std):\n",
    "    y_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "    y_true = data[\"target_positions\"].to(device)\n",
    "    MSE = F.mse_loss(y_hat, y_true, reduction='none')\n",
    "    # not all the output steps are valid, but we can filter them out from the loss using availabilities\n",
    "    MSE = MSE * y_availabilities\n",
    "    MSE = MSE.mean()\n",
    "    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n",
    "    var = torch.pow(torch.exp(std), 2)\n",
    "    KLD = -0.5 * torch.mean(1+torch.log(var)-torch.pow(mean, 2)-var)\n",
    "    return MSE+KLD\n",
    "\n",
    "\n",
    "# 创建对象\n",
    "cvae = CVAE().to(device)\n",
    "# vae.load_state_dict(torch.load('./VAE_z2.pth'))\n",
    "cvae_optimizer = torch.optim.Adam(cvae.parameters(),lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 72.44104766845703 loss(avg): 118.47555434566804:   2%|▌                     | 87/3489 [22:50<15:13:11, 16.11s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9db747c6b173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 设置为训练模式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 输入\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-bcb417ae904a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mout11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mout11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mout12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout11\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m#         print(out1.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;31m# See note [TorchScript super()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==== TRAIN LOOP\n",
    "losses_avg = []\n",
    "for epoch in range(epochs):  # 进行多个epoch的训练\n",
    "    tr_it = iter(train_dataloader)\n",
    "    progress_bar = tqdm(range(len(train_dataloader)),position=0)\n",
    "    losses_train = []\n",
    "    for _ in progress_bar:\n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataloader)\n",
    "            data = next(tr_it)\n",
    "        cvae.train() # 设置为训练模式\n",
    "        torch.set_grad_enabled(True)\n",
    "        y_hat, mean, std = cvae(data)  # 输入\n",
    "        loss = loss_function(y_hat, data, mean, std)\n",
    "\n",
    "        # Backward pass\n",
    "        cvae_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        cvae_optimizer.step()\n",
    "        losses_train.append(loss.item())\n",
    "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "    losses_avg.append(np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses_avg)), losses_avg, label=\"train loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "eval_zarr = ChunkedDataset(dm.require(eval_cfg[\"key\"])).open()\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "print(len(eval_dataset))\n",
    "print(eval_dataset)\n",
    "print(eval_dataset[0].keys())\n",
    "\n",
    "eval_dataset = MyTrainDataset(cfg, dm, len(eval_dataset))\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    shuffle=eval_cfg[\"shuffle\"], \n",
    "    batch_size=eval_cfg[\"batch_size\"],\n",
    "    num_workers=eval_cfg[\"num_workers\"],\n",
    "    persistent_workers=True,\n",
    "    worker_init_fn=my_dataset_worker_init_func\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==== EVAL LOOP\n",
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# store information for evaluation\n",
    "future_coords_offsets_pd = []\n",
    "gt_coords_offsets_pd = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "availability = []\n",
    "progress_bar = tqdm(eval_dataloader,position=0)\n",
    "\n",
    "for data in progress_bar:\n",
    "    y_hat, mean, std = cvae(data)\n",
    "#     print(data)\n",
    "    # convert agent coordinates into world offsets\n",
    "    agents_coords = y_hat.cpu().numpy()\n",
    "    gt_coords = data['target_positions'].numpy()\n",
    "    world_from_agents = data['world_from_agent'].numpy()\n",
    "    centroids = data[\"centroid\"].numpy()\n",
    "    coords_offset = transform_points(agents_coords, world_from_agents) - centroids[:, None, :2]\n",
    "    gt_offset = transform_points(gt_coords, world_from_agents) - centroids[:, None, :2]\n",
    "    \n",
    "    future_coords_offsets_pd.append(np.stack(coords_offset))\n",
    "    gt_coords_offsets_pd.append(np.stack(gt_offset))\n",
    "    timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "    agent_ids.append(data[\"track_id\"].numpy().copy())\n",
    "    availability.append(data[\"target_availabilities\"].numpy().copy())\n",
    "    \n",
    "pred_path = f\"{gettempdir()}/pred.csv\"\n",
    "eval_gt_path = f\"{gettempdir()}/gt.csv\"\n",
    "\n",
    "write_pred_csv(pred_path,\n",
    "               timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(future_coords_offsets_pd),\n",
    "              )\n",
    "\n",
    "write_gt_csv(eval_gt_path,timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(gt_coords_offsets_pd),avails=np.concatenate(availability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics_csv(eval_gt_path, pred_path, [\n",
    "                              neg_multi_log_likelihood, time_displace])\n",
    "for metric_name, metric_mean in metrics.items():\n",
    "    print(metric_name, metric_mean)\n",
    "FDE = metrics.item()['time_displace']\n",
    "print('FDE1s: {}, FDE3s: {}, FDE5s: {}, ADE1s: {}, ADE3s: {}, ADE5s: {} '.format(\n",
    "    FDE[9], FDE[29], FDE[49], np.mean(FDE[:10]), np.mean(FDE[:30]), np.mean(FDE[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# build a dict to retrieve future trajectories from GT\n",
    "gt_rows = {}\n",
    "for row in read_gt_csv(eval_gt_path):\n",
    "    gt_rows[row[\"track_id\"] + row[\"timestamp\"]] = row[\"coord\"]\n",
    "\n",
    "eval_ego_dataset = EgoDataset(cfg, eval_zarr, rasterizer)\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "\n",
    "for frame_number in range(99, len(eval_zarr.frames), 100):  # start from last frame of scene_0 and increase by 100\n",
    "    agent_indices = eval_dataset.get_frame_indices(frame_number) \n",
    "    if not len(agent_indices):\n",
    "        continue\n",
    "\n",
    "    # get AV point-of-view frame\n",
    "    data_ego = eval_ego_dataset[frame_number]\n",
    "    im_ego = rasterizer.to_rgb(data_ego[\"image\"].transpose(1, 2, 0))\n",
    "    center = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n",
    "    \n",
    "    predicted_positions = []\n",
    "    target_positions = []\n",
    "\n",
    "    for v_index in agent_indices:\n",
    "        data_agent = eval_dataset[v_index]\n",
    "        out_net = cvae(data_agent)\n",
    "        out_pos = out_net[0].reshape(-1, 2).detach().cpu().numpy()\n",
    "        # store absolute world coordinates\n",
    "        predicted_positions.append(transform_points(out_pos, data_agent[\"world_from_agent\"]))\n",
    "        # retrieve target positions from the GT and store as absolute coordinates\n",
    "        track_id, timestamp = data_agent[\"track_id\"], data_agent[\"timestamp\"]\n",
    "        target_positions.append(gt_rows[str(track_id) + str(timestamp)] + data_agent[\"centroid\"][:2])\n",
    "\n",
    "\n",
    "    # convert coordinates to AV point-of-view so we can draw them\n",
    "    predicted_positions = transform_points(np.concatenate(predicted_positions), data_ego[\"raster_from_world\"])\n",
    "    target_positions = transform_points(np.concatenate(target_positions), data_ego[\"raster_from_world\"])\n",
    "\n",
    "    draw_trajectory(im_ego, predicted_positions, PREDICTED_POINTS_COLOR)\n",
    "    draw_trajectory(im_ego, target_positions, TARGET_POINTS_COLOR)\n",
    "\n",
    "    plt.imshow(im_ego)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python {lgsvl}",
   "language": "python",
   "name": "lgsvl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
