{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\l5kit\\dataset\\select_agents.py:32: UserWarning: Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.However, writing the mask with this config may be inconsistent.\n",
      "  \"Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.\"\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict,Callable\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim,Tensor,unsqueeze\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50,resnet18\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mydataset import MyTrainDataset, my_dataset_worker_init_func\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, write_gt_csv, read_gt_csv\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace, average_displacement_error_mean, final_displacement_error_mean\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_version': 4, 'model_params': {'model_architecture': 'CVAE', 'latent_dim': 128, 'num_layers': 2, 'bidirectional': False, 'history_step_size': 1, 'history_num_frames': 49, 'future_step_size': 1, 'future_num_frames': 50, 'step_time': 0.1, 'render_ego_history': True}, 'raster_params': {'raster_size': [224, 224], 'pixel_size': [0.5, 0.5], 'ego_center': [0.25, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'train_data_loader': {'key': 'scenes/sample.zarr', 'batch_size': 16, 'shuffle': True, 'num_workers': 2}, 'val_data_loader': {'key': 'scenes/sample.zarr', 'batch_size': 16, 'shuffle': False, 'num_workers': 2}, 'train_params': {'device': 1, 'epochs': 1}}\n"
     ]
    }
   ],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"E:/Downloads/lyft-motion-prediction-autonomous-vehicles\"\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(\"./agent_motion_config.yaml\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111634\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|    100     |   24838    |  1893736   |     316008    |       0.69      |        248.38        |        76.24         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', 'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', 'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'curr_speed', 'scene_index', 'host_id', 'timestamp', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT DATASET\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "print(len(train_dataset))\n",
    "print(train_dataset)\n",
    "print(train_dataset[0].keys())\n",
    "\n",
    "train_dataset = MyTrainDataset(cfg, dm, len(train_dataset),raster_mode = 1)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=train_cfg[\"shuffle\"], \n",
    "    batch_size=train_cfg[\"batch_size\"],\n",
    "    num_workers=train_cfg[\"num_workers\"],\n",
    "    pin_memory = True,\n",
    "    persistent_workers=True,\n",
    "    worker_init_fn=my_dataset_worker_init_func\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "if cfg[\"train_params\"][\"device\"] == 1:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "epochs = cfg[\"train_params\"][\"epochs\"]\n",
    "latent_dim = cfg[\"model_params\"][\"latent_dim\"]  # LSTM 的单元个数\n",
    "num_layers = cfg[\"model_params\"][\"num_layers\"]\n",
    "bidirectional = cfg[\"model_params\"][\"bidirectional\"]\n",
    "num_classes = 3 # 类数\n",
    "encoder_length = cfg[\"model_params\"][\"history_num_frames\"]\n",
    "decoder_length = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2\n",
    "z_dimension = 16\n",
    "accumulation_steps = 3 # 梯度累积步数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "\n",
    "        # 定义编码器\n",
    "        self.encoder = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional,batch_first=True)\n",
    "        self.encoder2 = nn.Linear(latent_dim*(1+bidirectional), 16)\n",
    "#         self.encoder_mean1 = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.encoder_mean2 = nn.Linear(16*2, z_dimension)\n",
    "#         self.encoder_std1 = nn.Linear(latent_dim*(1+bidirectional), 32)\n",
    "        self.encoder_std2 = nn.Linear(16*2, z_dimension)\n",
    "\n",
    "        # 定义解码器\n",
    "        self.decoder = nn.LSTM(z_dimension, latent_dim, num_layers=num_layers,\n",
    "                               bidirectional=bidirectional,batch_first=True)\n",
    "        self.decoder_fc = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.decoder_fc1 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_fc2 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_fc3 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_confi = nn.Linear(64, num_classes)\n",
    "\n",
    "        # 道路特征提取器\n",
    "        # load pre-trained Conv2D model\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        # change input channels number to match the rasterizer's output\n",
    "        num_history_channels = (\n",
    "            cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.resnet.conv1.out_channels,\n",
    "            kernel_size=self.resnet.conv1.kernel_size,\n",
    "            stride=self.resnet.conv1.stride,\n",
    "            padding=self.resnet.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        # change output size to (X, Y) * number of future states\n",
    "        num_targets = 16 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=num_targets)\n",
    "\n",
    "    def noise_reparameterize(self, mean, logvar):\n",
    "        eps = torch.randn(mean.shape).to(device)\n",
    "        z = mean + eps * torch.exp(logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, data):\n",
    "        inputs1 = torch.FloatTensor(data[\"history_positions\"]).to(device)\n",
    "        if inputs1.dim() == 2:\n",
    "            inputs1.unsqueeze(0)\n",
    "#             inputs1.resize_(1, inputs1.size()[0], inputs1.size()[1])\n",
    "#         print(inputs.size())\n",
    "        h0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        c0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        inputs2 = torch.FloatTensor(data[\"image\"]).to(device)\n",
    "        if inputs2.dim() == 3:\n",
    "            inputs2.unsqueeze(0)\n",
    "#             inputs2.resize_(1, inputs2.size()[0], inputs2.size()[1], inputs2.size()[2])\n",
    "        out11, _ = self.encoder(inputs1, (h0, c0))\n",
    "        out11 = F.relu(self.encoder2(out11), inplace=True)\n",
    "        out12 = self.resnet(inputs2).reshape(out11.size())\n",
    "        out1 = torch.cat([out11, out12], 2)\n",
    "#         print(out1.size())\n",
    "#         mean1 = F.relu(self.encoder_mean1(out1), inplace=True)\n",
    "        mean2 = F.relu(self.encoder_mean2(out1), inplace=True)\n",
    "#         logstd1 = F.relu(self.encoder_std1(out1), inplace=True)\n",
    "        logstd2 = F.relu(self.encoder_std2(out1), inplace=True)\n",
    "        z = self.noise_reparameterize(mean2, logstd2)\n",
    "        out2, _ = self.decoder(z)\n",
    "        out2 = F.relu(self.decoder_fc(out2), inplace=True)\n",
    "        \n",
    "        out21 = F.relu(self.decoder_fc1(out2), inplace=True)\n",
    "#         out21 = out21.view(out21.size()[0],1,decoder_length,num_decoder_tokens)\n",
    "        out21 = torch.unsqueeze(out21,1)\n",
    "        out22 = F.relu(self.decoder_fc2(out2), inplace=True)\n",
    "        out22 = torch.unsqueeze(out22,1)\n",
    "#         out22 = out22.view(out22.size()[0],1,decoder_length,num_decoder_tokens)\n",
    "        out23 = F.relu(self.decoder_fc3(out2), inplace=True)\n",
    "        out23 = torch.unsqueeze(out23,1)\n",
    "#         out23 = out23.view(out23.size()[0],1,decoder_length,num_decoder_tokens)\n",
    "        \n",
    "        confidences = F.softmax(self.decoder_confi(out2)[:,-1,:])\n",
    "        y_hat = torch.cat([out21,out22,out23],dim=1)\n",
    "#         print(confidences)\n",
    "        return y_hat, confidences, mean2, logstd2\n",
    "\n",
    "\n",
    "def loss_function(y_hat, confidences, data, mean, std):\n",
    "    y_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    y_true = data[\"target_positions\"].to(device)\n",
    "#     MSE = F.mse_loss(y_hat, y_true, reduction='none')\n",
    "#     MSE = MSE * y_availabilities\n",
    "#     MSE = MSE.mean()\n",
    "    NLL = neg_multi_log_likelihood_batch(y_true, y_hat, confidences, y_availabilities)\n",
    "    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n",
    "    var = torch.pow(torch.exp(std), 2)\n",
    "    KLD = -0.5 * torch.mean(1+torch.log(var)-torch.pow(mean, 2)-var)\n",
    "    return NLL + 1000*KLD\n",
    "\n",
    "\n",
    "# 创建对象\n",
    "cvae = CVAE().to(device)\n",
    "# vae.load_state_dict(torch.load('./VAE_z2.pth'))\n",
    "cvae_optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]D:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 3493.207763671875 loss(avg): 2295.1407368977866: 100%|█████████████████████████████| 6/6 [00:16<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# ==== TRAIN LOOP\n",
    "losses_avg = []\n",
    "for epoch in range(epochs):  # 进行多个epoch的训练\n",
    "    tr_it = iter(train_dataloader)\n",
    "    progress_bar = tqdm(range(len(train_dataloader)//1000),position=0)\n",
    "    losses_train = []\n",
    "    cvae_optimizer.zero_grad(set_to_none = True)\n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            data = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(train_dataloader)\n",
    "            data = next(tr_it)\n",
    "        cvae.train() # 设置为训练模式\n",
    "        torch.set_grad_enabled(True)\n",
    "        y_hat, confidences, mean, std = cvae(data)  # 输入\n",
    "        if cfg[\"train_params\"][\"device\"] == 1:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss = loss_function(y_hat, confidences, data, mean, std)\n",
    "        else:\n",
    "            loss = loss_function(y_hat, confidences, data, mean, std)\n",
    "\n",
    "        # Backward pass\n",
    "        # 梯度累积模式\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward() \n",
    "        if (i+1) % accumulation_steps == 0:\n",
    "            cvae_optimizer.step()\n",
    "            cvae_optimizer.zero_grad(set_to_none = True)\n",
    "            \n",
    "        # 无梯度累积模式\n",
    "#         cvae_optimizer.zero_grad(set_to_none = True)\n",
    "#         loss.backward()\n",
    "#         cvae_optimizer.step()\n",
    "        losses_train.append(loss.item())\n",
    "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "    losses_avg.append(np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(losses_avg)), losses_avg, label=\"train loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111634\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|    100     |   24838    |  1893736   |     316008    |       0.69      |        248.38        |        76.24         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', 'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', 'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'curr_speed', 'scene_index', 'host_id', 'timestamp', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "eval_zarr = ChunkedDataset(dm.require(eval_cfg[\"key\"])).open()\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "print(len(eval_dataset))\n",
    "print(eval_dataset)\n",
    "print(eval_dataset[0].keys())\n",
    "\n",
    "eval_dataset = MyTrainDataset(cfg, dm, len(eval_dataset),raster_mode = 1)\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    shuffle=eval_cfg[\"shuffle\"], \n",
    "    batch_size=eval_cfg[\"batch_size\"],\n",
    "    num_workers=eval_cfg[\"num_workers\"],\n",
    "    persistent_workers=True,\n",
    "    worker_init_fn=my_dataset_worker_init_func\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/6978 [00:00<?, ?it/s]D:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      " 55%|█████████████████████████████████████████▉                                  | 3847/6978 [1:14:43<54:34,  1.05s/it]"
     ]
    }
   ],
   "source": [
    "# ==== EVAL LOOP\n",
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# store information for evaluation\n",
    "future_coords_offsets_pd = []\n",
    "gt_coords_offsets_pd = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "availability = []\n",
    "progress_bar = tqdm(train_dataloader,position=0)\n",
    "\n",
    "for data in progress_bar:\n",
    "    y_hat, confidences,_,_ = cvae(data)\n",
    "#     print(data)\n",
    "    # convert agent coordinates into world offsets\n",
    "    confs = confidences.detach().cpu().numpy()\n",
    "    agents_coords = y_hat.detach().cpu().numpy()\n",
    "    gt_coords = data['target_positions'].numpy()\n",
    "    world_from_agents = data['world_from_agent'].numpy()\n",
    "    centroids = data[\"centroid\"].numpy()\n",
    "    coords_offset1 = transform_points(agents_coords[:,0,:,:], world_from_agents) - centroids[:, None, :2]\n",
    "    coords_offset2 = transform_points(agents_coords[:,1,:,:], world_from_agents) - centroids[:, None, :2]\n",
    "    coords_offset3 = transform_points(agents_coords[:,2,:,:], world_from_agents) - centroids[:, None, :2]\n",
    "    coords_offset = np.stack([coords_offset1,coords_offset2,coords_offset3],1)\n",
    "    gt_offset = transform_points(gt_coords, world_from_agents) - centroids[:, None, :2]\n",
    "    \n",
    "    future_coords_offsets_pd.append(np.stack(coords_offset))\n",
    "    gt_coords_offsets_pd.append(np.stack(gt_offset))\n",
    "    timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "    agent_ids.append(data[\"track_id\"].numpy().copy())\n",
    "    availability.append(data[\"target_availabilities\"].numpy().copy())\n",
    "    \n",
    "pred_path = \"/pred.csv\"\n",
    "eval_gt_path = \"/gt.csv\"\n",
    "\n",
    "write_pred_csv(pred_path,\n",
    "               timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(future_coords_offsets_pd),\n",
    "               confs=np.concatenate(confs)\n",
    "              )\n",
    "\n",
    "write_gt_csv(eval_gt_path,timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(gt_coords_offsets_pd),avails=np.concatenate(availability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics_csv(eval_gt_path, pred_path, [\n",
    "                              neg_multi_log_likelihood, time_displace])\n",
    "for metric_name, metric_mean in metrics.items():\n",
    "    print(metric_name, metric_mean)\n",
    "    if metric_name==\"time_displace\":\n",
    "        FDE = metric_mean\n",
    "print('FDE1s: {}, FDE3s: {}, FDE5s: {}, ADE1s: {}, ADE3s: {}, ADE5s: {} '.format(\n",
    "    FDE[9], FDE[29], FDE[49], np.mean(FDE[:10]), np.mean(FDE[:30]), np.mean(FDE[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# build a dict to retrieve future trajectories from GT\n",
    "gt_rows = {}\n",
    "for row in read_gt_csv(eval_gt_path):\n",
    "    gt_rows[row[\"track_id\"] + row[\"timestamp\"]] = row[\"coord\"]\n",
    "\n",
    "eval_ego_dataset = EgoDataset(cfg, eval_zarr, rasterizer)\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "\n",
    "for frame_number in range(99, len(eval_zarr.frames), 100):  # start from last frame of scene_0 and increase by 100\n",
    "    agent_indices = eval_dataset.get_frame_indices(frame_number) \n",
    "    if not len(agent_indices):\n",
    "        continue\n",
    "\n",
    "    # get AV point-of-view frame\n",
    "    data_ego = eval_ego_dataset[frame_number]\n",
    "    im_ego = rasterizer.to_rgb(data_ego[\"image\"].transpose(1, 2, 0))\n",
    "    center = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n",
    "    \n",
    "    predicted_positions = []\n",
    "    target_positions = []\n",
    "\n",
    "    for v_index in agent_indices:\n",
    "        data_agent = eval_dataset[v_index]\n",
    "        out_net,confs = cvae(data_agent)\n",
    "        confs = confs.detach().cpu().numpy()\n",
    "        out_net = out_net[0][np.argmax(confs)]\n",
    "        out_pos = out_net.reshape(-1, 2).detach().cpu().numpy()\n",
    "        # store absolute world coordinates\n",
    "        predicted_positions.append(transform_points(out_pos, data_agent[\"world_from_agent\"]))\n",
    "        # retrieve target positions from the GT and store as absolute coordinates\n",
    "        track_id, timestamp = data_agent[\"track_id\"], data_agent[\"timestamp\"]\n",
    "        target_positions.append(gt_rows[str(track_id) + str(timestamp)] + data_agent[\"centroid\"][:2])\n",
    "\n",
    "\n",
    "    # convert coordinates to AV point-of-view so we can draw them\n",
    "    predicted_positions = transform_points(np.concatenate(predicted_positions), data_ego[\"raster_from_world\"])\n",
    "    target_positions = transform_points(np.concatenate(target_positions), data_ego[\"raster_from_world\"])\n",
    "\n",
    "    draw_trajectory(im_ego, predicted_positions, PREDICTED_POINTS_COLOR)\n",
    "    draw_trajectory(im_ego, target_positions, TARGET_POINTS_COLOR)\n",
    "\n",
    "    plt.imshow(im_ego)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python {lgsvl}",
   "language": "python",
   "name": "lgsvl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
