{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\lgsvl\\lib\\site-packages\\l5kit\\dataset\\select_agents.py:32: UserWarning: Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.However, writing the mask with this config may be inconsistent.\n",
      "  \"Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.\"\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict,Callable\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim,Tensor,unsqueeze\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50,resnet18\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mydataset import MyTrainDataset, my_dataset_worker_init_func\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, write_gt_csv, read_gt_csv\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace, average_displacement_error_mean, final_displacement_error_mean\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_version': 4, 'mode': {'load_mode': False}, 'model_params': {'model_architecture': 'CVAE', 'latent_dim': 256, 'num_layers': 2, 'bidirectional': True, 'history_step_size': 1, 'history_num_frames': 49, 'future_step_size': 1, 'future_num_frames': 50, 'step_time': 0.1, 'render_ego_history': True}, 'raster_params': {'raster_mode': 0, 'raster_size': [112, 112], 'pixel_size': [0.75, 0.75], 'ego_center': [0.25, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'train_data_loader': {'key': 'scenes/train.zarr', 'batch_size': 32, 'shuffle': True, 'num_workers': 2}, 'val_data_loader': {'key': 'scenes/validate.zarr', 'batch_size': 32, 'shuffle': False, 'num_workers': 2}, 'train_params': {'device': 1, 'epochs': 1}}\n"
     ]
    }
   ],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"E:/Downloads/lyft-motion-prediction-autonomous-vehicles\"\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(\"./agent_motion_config.yaml\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22496709\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', 'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', 'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'curr_speed', 'scene_index', 'host_id', 'timestamp', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "if not cfg['mode']['load_mode']:    \n",
    "    # ===== INIT DATASET\n",
    "    train_cfg = cfg[\"train_data_loader\"]\n",
    "    rasterizer = build_rasterizer(cfg, dm)\n",
    "    train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "    train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "    print(len(train_dataset))\n",
    "    print(train_dataset)\n",
    "    print(train_dataset[0].keys())\n",
    "\n",
    "    train_dataset = MyTrainDataset(cfg, dm, len(train_dataset),raster_mode = cfg[\"raster_params\"][\"raster_mode\"])\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=train_cfg[\"shuffle\"], \n",
    "        batch_size=train_cfg[\"batch_size\"],\n",
    "        num_workers=train_cfg[\"num_workers\"],\n",
    "        prefetch_factor = 2,\n",
    "        pin_memory = True,\n",
    "        persistent_workers=True,\n",
    "        worker_init_fn=my_dataset_worker_init_func\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "if cfg[\"train_params\"][\"device\"] == 1:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "epochs = cfg[\"train_params\"][\"epochs\"]\n",
    "latent_dim = cfg[\"model_params\"][\"latent_dim\"]  # LSTM 的单元个数\n",
    "encoder_fc = 64\n",
    "num_layers = cfg[\"model_params\"][\"num_layers\"]\n",
    "bidirectional = cfg[\"model_params\"][\"bidirectional\"]\n",
    "num_classes = 3 # 类数\n",
    "encoder_length = cfg[\"model_params\"][\"history_num_frames\"]\n",
    "decoder_length = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2\n",
    "z_dimension = 32\n",
    "accumulation_steps = 5 # 梯度累积步数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "\n",
    "        self.lstm1 = nn.LSTM(num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.fc = nn.Linear(latent_dim*(1+bidirectional), num_decoder_tokens)\n",
    "\n",
    "    def forward(self, data):\n",
    "        inputs1 = torch.FloatTensor(data[\"history_positions\"]).to(device)\n",
    "        if inputs1.dim() == 2:\n",
    "            inputs1 = torch.unsqueeze(inputs1,0)\n",
    "\n",
    "        h0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        c0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "\n",
    "        _,(h,c) = self.lstm1(inputs1, (h0, c0))\n",
    "        y_hat,(_,_) = self.lstm2(inputs1, (h, c))\n",
    "        y_hat = torch.tanh(self.fc(y_hat))\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "def loss_function(y_hat, data):\n",
    "    y_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "    y_true = data[\"target_positions\"].to(device)\n",
    "    MSE = F.mse_loss(y_hat, y_true, reduction='none')\n",
    "    MSE = MSE * y_availabilities\n",
    "    MSE = MSE.mean()\n",
    "    return MSE\n",
    "\n",
    "\n",
    "# 创建对象\n",
    "cvae = CVAE().to(device)\n",
    "cvae_optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 12.946995735168457 loss(avg): 22.773940028905322: 100%|██████████████████████| 7030/7030 [23:25<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "if not cfg['mode']['load_mode']:    \n",
    "    # ==== TRAIN LOOP\n",
    "    losses_avg = []\n",
    "    for epoch in range(epochs):  # 进行多个epoch的训练\n",
    "        tr_it = iter(train_dataloader)\n",
    "        progress_bar = tqdm(range(len(train_dataloader)//100),position=0)\n",
    "        losses_train = []\n",
    "        cvae_optimizer.zero_grad(set_to_none = True)\n",
    "        for i in progress_bar:\n",
    "            try:\n",
    "                data = next(tr_it)\n",
    "            except StopIteration:\n",
    "                tr_it = iter(train_dataloader)\n",
    "                data = next(tr_it)\n",
    "            cvae.train() # 设置为训练模式\n",
    "            torch.set_grad_enabled(True)\n",
    "            y_hat = cvae(data)  # 输入\n",
    "            if cfg[\"train_params\"][\"device\"] == 1:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss = loss_function(y_hat, data)\n",
    "            else:\n",
    "                loss = loss_function(y_hat, data)\n",
    "\n",
    "            # Backward pass\n",
    "            # 梯度累积模式\n",
    "            loss = loss / accumulation_steps\n",
    "            loss.backward() \n",
    "            if (i+1) % accumulation_steps == 0:\n",
    "                cvae_optimizer.step()\n",
    "                cvae_optimizer.zero_grad(set_to_none = True)\n",
    "\n",
    "            # 无梯度累积模式\n",
    "    #         cvae_optimizer.zero_grad(set_to_none = True)\n",
    "    #         loss.backward()\n",
    "    #         cvae_optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "            progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "        losses_avg.append(np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not cfg['mode']['load_mode']:    \n",
    "    torch.save(cvae.state_dict(),'E:/Downloads/cvae.pth')\n",
    "    plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg['mode']['load_mode'] and cfg['train_params']['epochs'] > 1: \n",
    "    plt.plot(np.arange(len(losses_avg)), losses_avg, label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21624612\n",
      "dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', 'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', 'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'curr_speed', 'scene_index', 'host_id', 'timestamp', 'track_id'])\n",
      "675770\n"
     ]
    }
   ],
   "source": [
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "eval_zarr = ChunkedDataset(dm.require(eval_cfg[\"key\"])).open()\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "print(len(eval_dataset))\n",
    "print(eval_dataset[0].keys())\n",
    "\n",
    "eval_dataset = MyTrainDataset(cfg, dm, len(eval_dataset),raster_mode = cfg[\"raster_params\"][\"raster_mode\"])\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    shuffle=eval_cfg[\"shuffle\"], \n",
    "    batch_size=eval_cfg[\"batch_size\"],\n",
    "    num_workers=eval_cfg[\"num_workers\"],\n",
    "    prefetch_factor = 2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory = True,\n",
    "    worker_init_fn=my_dataset_worker_init_func\n",
    ")\n",
    "\n",
    "print(len(eval_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6757/6757 [22:15<00:00,  4.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==== EVAL LOOP\n",
    "cvae.load_state_dict(torch.load('E:/Downloads/cvae.pth'))\n",
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# store information for evaluation\n",
    "future_coords_offsets_pd = []\n",
    "gt_coords_offsets_pd = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "availability = []\n",
    "confs = []\n",
    "tr_it = iter(eval_dataloader)\n",
    "progress_bar = tqdm(range(len(eval_dataloader)//100),position=0)\n",
    "\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(eval_dataloader)\n",
    "        data = next(tr_it)\n",
    "    y_hat = cvae(data)\n",
    "#     print(data)\n",
    "    # convert agent coordinates into world offsets\n",
    "    agents_coords = y_hat.detach().cpu().numpy()\n",
    "    gt_coords = data['target_positions'].numpy()\n",
    "    world_from_agents = data['world_from_agent'].numpy()\n",
    "    centroids = data[\"centroid\"].numpy()\n",
    "    coords_offset = transform_points(agents_coords, world_from_agents) - centroids[:, None, :2]\n",
    "    gt_offset = transform_points(gt_coords, world_from_agents) - centroids[:, None, :2]\n",
    "    \n",
    "    future_coords_offsets_pd.append(np.stack(coords_offset))\n",
    "    gt_coords_offsets_pd.append(np.stack(gt_offset))\n",
    "    timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "    agent_ids.append(data[\"track_id\"].numpy().copy())\n",
    "    availability.append(data[\"target_availabilities\"].numpy().copy())\n",
    "\n",
    "    \n",
    "pred_path = \"E:/Downloads/pred.csv\"\n",
    "eval_gt_path = \"E:/Downloads/gt.csv\"\n",
    "\n",
    "write_pred_csv(pred_path,\n",
    "               timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(future_coords_offsets_pd),\n",
    "              )\n",
    "\n",
    "write_gt_csv(eval_gt_path,timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(gt_coords_offsets_pd),avails=np.concatenate(availability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_multi_log_likelihood 5605.5154354555825\n",
      "time_displace [0.14934968 0.39351425 0.69960158 1.01122067 1.32256336 1.63201618\n",
      " 1.93803149 2.2396201  2.53652848 2.82797827 3.11347802 3.39269309\n",
      " 3.6658555  3.93297081 4.19425119 4.44860251 4.69664221 4.93859927\n",
      " 5.17345784 5.4020932  5.62612583 5.84375523 6.05499292 6.26021491\n",
      " 6.45951039 6.65461216 6.84393481 7.02697113 7.20337357 7.37527757\n",
      " 7.5398536  7.70060671 7.85832902 8.00889419 8.1532449  8.29348225\n",
      " 8.4291724  8.5609125  8.68753875 8.8113905  8.93152674 9.04927095\n",
      " 9.16304907 9.27430196 9.38397673 9.49064446 9.59341601 9.69193193\n",
      " 9.78827906 9.88101333]\n",
      "FDE1s: 2.8279782674393172, FDE3s: 7.375277571746288, FDE5s: 9.881013329135396, ADE1s: 1.4750424064953362, ADE3s: 4.101927874387499, ADE5s: 5.986973426139153 \n"
     ]
    }
   ],
   "source": [
    "metrics = compute_metrics_csv(eval_gt_path, pred_path, [\n",
    "                              neg_multi_log_likelihood, time_displace])\n",
    "for metric_name, metric_mean in metrics.items():\n",
    "    print(metric_name, metric_mean)\n",
    "    if metric_name==\"time_displace\":\n",
    "        FDE = metric_mean\n",
    "print('FDE1s: {}, FDE3s: {}, FDE5s: {}, ADE1s: {}, ADE3s: {}, ADE5s: {} '.format(\n",
    "    FDE[9], FDE[29], FDE[49], np.mean(FDE[:10]), np.mean(FDE[:30]), np.mean(FDE[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'11576254980902731486'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b40684305aa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# retrieve target positions from the GT and store as absolute coordinates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtrack_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_agent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"track_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_agent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mtarget_positions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_rows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_agent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"centroid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '11576254980902731486'"
     ]
    }
   ],
   "source": [
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# build a dict to retrieve future trajectories from GT\n",
    "gt_rows = {}\n",
    "for row in read_gt_csv(eval_gt_path):\n",
    "    gt_rows[row[\"track_id\"] + row[\"timestamp\"]] = row[\"coord\"]\n",
    "\n",
    "eval_ego_dataset = EgoDataset(cfg, eval_zarr, rasterizer)\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "\n",
    "for frame_number in range(99, len(eval_zarr.frames), 100):  # start from last frame of scene_0 and increase by 100\n",
    "    agent_indices = eval_dataset.get_frame_indices(frame_number) \n",
    "    if not len(agent_indices):\n",
    "        continue\n",
    "\n",
    "    # get AV point-of-view frame\n",
    "    data_ego = eval_ego_dataset[frame_number]\n",
    "    im_ego = rasterizer.to_rgb(data_ego[\"image\"].transpose(1, 2, 0))\n",
    "    center = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n",
    "    \n",
    "    predicted_positions = []\n",
    "    predicted_positions1 = []\n",
    "    predicted_positions2 = []\n",
    "    predicted_positions3 = []\n",
    "    target_positions = []\n",
    "\n",
    "    for v_index in agent_indices:\n",
    "        data_agent = eval_dataset[v_index]\n",
    "        out_net = cvae(data_agent)\n",
    "        out_net = out_net[0]\n",
    "        out_pos = out_net.reshape(-1, 2).detach().cpu().numpy()\n",
    "        # store absolute world coordinates\n",
    "        predicted_positions.append(transform_points(out_pos, data_agent[\"world_from_agent\"]))\n",
    "        # retrieve target positions from the GT and store as absolute coordinates\n",
    "        track_id, timestamp = data_agent[\"track_id\"], data_agent[\"timestamp\"]\n",
    "        target_positions.append(gt_rows[str(track_id) + str(timestamp)] + data_agent[\"centroid\"][:2])\n",
    "\n",
    "\n",
    "    # convert coordinates to AV point-of-view so we can draw them\n",
    "    predicted_positions = transform_points(np.concatenate(predicted_positions), data_ego[\"raster_from_world\"])\n",
    "    target_positions = transform_points(np.concatenate(target_positions), data_ego[\"raster_from_world\"])\n",
    "\n",
    "    draw_trajectory(im_ego, target_positions, TARGET_POINTS_COLOR)\n",
    "    draw_trajectory(im_ego, predicted_positions, PREDICTED_POINTS_COLOR)\n",
    "\n",
    "\n",
    "    plt.imshow(im_ego)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python {lgsvl}",
   "language": "python",
   "name": "lgsvl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
